\prefacesection{Abstract}
Imagine a world where ubiquitous sensors are constantly monitoring your health and predicting whether you are at risk for a life threatening condition.  If such a condition is detected, you receive a notification to get further testing.  Many life threatening conditions can be cured if treated early enough.  Further, many life threatening conditions are obvious to a trained medical expert.  Can the recent advances in AI be leveraged to distill some of this highly valuable medical expertise?  If so, it could be distributed widely, run all the time, and cost little more than the electricity that runs it.  In this thesis I argue that future is not so distant.  

Chapter 2 examines results in detecting skin cancer from photos.  These photos can be taken by any smartphone.  Board-certified dermatologist level performance is demonstrated.

Chapter 3 examines results in assessing risk for a wide range of conditions affecting the heart and other internal organs.  Risk is assessed from waveform signals measured in the hospital such as electrocardiogram, photoplethysmogram, and others.  Modern smartwatches can measure both an electrocardiogram and a photoplethysmogram.  The problem of how to deal with unreliable but not uninformative classifiers is examined.  Additionally a semantic map of diseases is generated.  The embedding of diseases appears to be organized by organ (heart, liver, brain, etc).  The neural net learned this as a byproduct of being trained to detect diseases from raw waveforms.